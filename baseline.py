# -*- coding: utf-8 -*-
import os
import random
import operator
import csv
import pandas as pd
from SQLParser import parse_sql
from deap import base, creator, gp, tools, algorithms
from copy import deepcopy

# =========================
#  é€‰æ‹©ç‡ä¸è¡Œæ•°åŠ è½½ï¼ˆä¿æŒä¸å˜ï¼‰
# =========================
def load_selectivity_with_rows(xlsx_path):
    df = pd.read_excel(xlsx_path, header=None)
    selectivity_map = {}
    table_rows = {}
    for _, row in df.iterrows():
        t1 = str(row[0]).strip()
        t2 = str(row[1]).strip()
        rows1 = int(row[2])
        rows2 = int(row[3])
        sel = float(row[4])
        key = frozenset([t1, t2])
        selectivity_map[key] = sel
        table_rows[t1] = rows1
        table_rows[t2] = rows2
    return selectivity_map, table_rows

# =========================
#  GP åŸºå…ƒï¼šJOIN æ ‘ï¼ˆä¿æŒä¸å˜ï¼‰
# =========================
def join_tables(a, b):
    return ("JOIN", a, b)

def create_pset(table_list):
    pset = gp.PrimitiveSet("MAIN", 0)
    pset.addPrimitive(join_tables, 2, name="join_tables")
    for table in table_list:
        pset.addTerminal(table, name=str(table))
    return pset

# éšæœºç”Ÿæˆä¿æŒâ€œæ¯è¡¨æ°å¥½ä¸€æ¬¡â€çš„åˆå§‹ JOIN æ ‘ï¼ˆéšæœºå½¢çŠ¶ï¼‰ï¼ˆä¿æŒä¸å˜ï¼‰
def generate_expr_unique_terminals(pset, table_list, rng):
    shuffled = rng.sample(table_list, len(table_list))

    def build_tree(tables):
        if len(tables) == 1:
            return tables[0]
        split = rng.randint(1, len(tables) - 1)
        left = build_tree(tables[:split])
        right = build_tree(tables[split:])
        return ("JOIN", left, right)

    def tree_to_str(t):
        if isinstance(t, str):
            return t
        return f"join_tables({tree_to_str(t[1])}, {tree_to_str(t[2])})"

    tree = build_tree(shuffled)
    expr_str = tree_to_str(tree)
    return gp.PrimitiveTree.from_string(expr_str, pset)


def generate_expr_connected(pset, table_list, allowed_edges, rng):
    # éšæœºå½¢çŠ¶ä½¿ç”¨å±€éƒ¨ rng
    base = generate_expr_unique_terminals(pset, table_list, rng)
    shape = parse_gp_str(str(base))
    if len(leaves_inorder(shape)) != len(table_list):
        return base  # é€€å›åŸå§‹å½¢çŠ¶
    # å¶åºä½¿ç”¨ç¡®å®šæ€§è´ªå¿ƒ
    order = build_greedy_connected_order(table_list, allowed_edges)
    expr_str = tuple_to_expr_str(fill_leaves_with_order(shape, iter(order)))
    return gp.PrimitiveTree.from_string(expr_str, pset)

# =========================
#  æ ‘è§£æ/é‡å»º/å¶åºï¼ˆä¿æŒä¸å˜ï¼‰
# =========================
def parse_gp_str(expr_str: str):
    expr_str = expr_str.strip()
    if not expr_str.startswith("join_tables"):
        return expr_str
    inside = expr_str[len("join_tables("):-1]
    depth = 0
    split_index = None
    for i, ch in enumerate(inside):
        if ch == "(":
            depth += 1
        elif ch == ")":
            depth -= 1
        elif ch == "," and depth == 0:
            split_index = i
            break
    left_str = inside[:split_index].strip()
    right_str = inside[split_index+1:].strip()
    return ("JOIN", parse_gp_str(left_str), parse_gp_str(right_str))

def tuple_to_expr_str(t):
    if isinstance(t, str):
        return t
    _, l, r = t
    return f"join_tables({tuple_to_expr_str(l)}, {tuple_to_expr_str(r)})"

def leaves_inorder(t):
    if isinstance(t, str):
        return [t]
    return leaves_inorder(t[1]) + leaves_inorder(t[2])

def get_all_tables(subtree):
    if isinstance(subtree, str):
        return [subtree]
    if isinstance(subtree, tuple) and subtree[0] == "JOIN":
        return get_all_tables(subtree[1]) + get_all_tables(subtree[2])
    return []

def fill_leaves_with_order(shape_tuple, order_iter):
    if isinstance(shape_tuple, str):
        return next(order_iter)
    _, l, r = shape_tuple
    return ("JOIN",
            fill_leaves_with_order(l, order_iter),
            fill_leaves_with_order(r, order_iter))

def get_leaf_order_from_ind(individual):
    return leaves_inorder(parse_gp_str(str(individual)))

# =========================
#  å˜å¼‚ï¼ˆä¿æŒä¸ºâ€œä¸çˆ¶æ—‹è½¬â€çš„ mutate2ï¼‰
# =========================
def mutate_individual(individual, pset, table_list, max_tries=10):
    """
    è®ºæ–‡çš„ mutate2 æ€æƒ³ï¼šéšæœºæŒ‘ä¸€ä¸ªå†…éƒ¨èŠ‚ç‚¹ï¼Œä¸å…¶çˆ¶èŠ‚ç‚¹åšä¸€æ¬¡æ—‹è½¬ï¼ˆå·¦æ—‹/å³æ—‹ï¼‰ï¼Œ
    ç»“æ„å¾®è°ƒï¼Œä¸æ”¹å˜å¶é›†åˆã€‚å¤±è´¥åˆ™åŸæ ·è¿”å›ã€‚
    """
    def _get_sub(t, path):
        if not path:
            return t
        _, l, r = t
        return _get_sub(l, path[1:]) if path[0] == 'L' else _get_sub(r, path[1:])

    def _set_sub(t, path, new_sub):
        if not path:
            return new_sub
        _, l, r = t
        if path[0] == 'L':
            return ("JOIN", _set_sub(l, path[1:], new_sub), r)
        else:
            return ("JOIN", l, _set_sub(r, path[1:], new_sub))

    def _list_internal_paths(t, path=()):
        if isinstance(t, str):
            return []
        _, l, r = t
        paths = [path]
        paths += _list_internal_paths(l, path + ('L',))
        paths += _list_internal_paths(r, path + ('R',))
        return paths

    def _rotate_with_parent(t, target_path):
        if not target_path:
            return None  # æ ¹æ— çˆ¶
        parent_path = target_path[:-1]
        is_left = (target_path[-1] == 'L')
        parent = _get_sub(t, parent_path)
        if isinstance(parent, str):
            return None
        _, A, B = parent  # parent = ("JOIN", A, B)

        target = A if is_left else B
        if isinstance(target, str):
            return None
        _, x, y = target  # target = ("JOIN", x, y)

        if is_left:
            # å³æ—‹ï¼š( (x,y), B ) -> ( x, (y,B) )
            new_parent = ("JOIN", x, ("JOIN", y, B))
        else:
            # å·¦æ—‹ï¼š( A, (x,y) ) -> ( (A,x), y )
            new_parent = ("JOIN", ("JOIN", A, x), y)

        return _set_sub(t, parent_path, new_parent)

    t = parse_gp_str(str(individual))
    internal_paths = [p for p in _list_internal_paths(t) if len(p) > 0]  # éæ ¹
    if not internal_paths:
        return creator.Individual(gp.PrimitiveTree(individual)),

    tries = 0
    while tries < max_tries:
        tries += 1
        p = random.choice(internal_paths)
        new_t = _rotate_with_parent(t, p)
        if new_t is not None and tuple_to_expr_str(new_t) != tuple_to_expr_str(t):
            expr = gp.PrimitiveTree.from_string(tuple_to_expr_str(new_t), pset)
            return creator.Individual(expr),
    return creator.Individual(gp.PrimitiveTree(individual)),

# =========================
#  è®ºæ–‡å¼ Ï†-äº¤å‰ï¼šå·¥å…·å‡½æ•°
# =========================
def leaves_set(node):
    if isinstance(node, str):
        return {node}
    _, l, r = node
    return leaves_set(l) | leaves_set(r)

def postorder_join_descriptors(t):
    """
    è¿”å›æŒ‰ååºçš„ join æè¿°åˆ—è¡¨ï¼šæ¯ä¸ªå…ƒç´ æ˜¯ (Lset, Rset)ï¼Œ
    å…¶ä¸­ Lset/Rset æ˜¯è¯¥ join å·¦/å³å­æ ‘çš„å¶é›†åˆï¼ˆé›†åˆå¯¹è±¡ã€å¯ä½œåŒ¹é…é”®ï¼‰ã€‚
    """
    out = []
    def rec(n):
        if isinstance(n, str):
            return
        _, l, r = n
        rec(l); rec(r)
        out.append((frozenset(leaves_set(l)), frozenset(leaves_set(r))))
    rec(t)
    return out

def descriptors_for_subtree(t):
    return set(postorder_join_descriptors(t))

def phi_rebuild(nodelist, T_set):
    """
    è®ºæ–‡ Ï† ç®—å­ï¼šé€æ­¥ä» T_set å–å‡ºä¸ (Lset,Rset) åŒ¹é…çš„ä¸¤æ£µæ ‘ï¼Œç»„åˆä¸ºæ–° JOIN æ ‘ã€‚
    """
    def keyset(tree):
        return frozenset(leaves_set(tree))

    pool = {}
    def push(tree):
        pool.setdefault(keyset(tree), []).append(tree)
    def pop_exact(key):
        lst = pool.get(key, [])
        if not lst:
            return None
        return lst.pop()

    for t in T_set:
        push(t)

    for (Lset, Rset) in nodelist:
        A = pop_exact(Lset)
        B = pop_exact(Rset)
        if A is None or B is None:
            return None
        push(("JOIN", A, B))

    # æœ€ååº”åªå‰© 1 æ£µæ ‘
    leftover = None
    for lst in pool.values():
        for el in lst:
            if leftover is None:
                leftover = el
            else:
                return None
    return leftover

def pick_random_proper_subtree(t):
    subs = []
    def rec(n, is_root):
        if isinstance(n, str):
            return
        _, l, r = n
        if not is_root:
            subs.append(n)
        rec(l, False); rec(r, False)
    rec(t, True)
    if not subs:
        return None
    return random.choice(subs)

# =========================
#  è¿é€š/æœ‰æ•ˆæ€§ç›¸å…³ï¼ˆä¿æŒä¸å˜ï¼‰
# =========================
def _tabs(node):
    if isinstance(node, str):
        return [node]
    return _tabs(node[1]) + _tabs(node[2])

def build_allowed_edges(selectivity_map, table_list):
    tables = set(table_list)
    return {pair for pair in selectivity_map.keys() if all(t in tables for t in pair)}

def _has_allowed_edge_between_sets(left_tabs, right_tabs, allowed_edges):
    for l in left_tabs:
        for r in right_tabs:
            if frozenset([l, r]) in allowed_edges:
                return True
    return False

def count_disconnected_joins(tree, allowed_edges):
    if isinstance(tree, str):
        return 0
    _, L, R = tree
    left_tabs = _tabs(L); right_tabs = _tabs(R)
    bad = 0 if _has_allowed_edge_between_sets(left_tabs, right_tabs, allowed_edges) else 1
    return bad + count_disconnected_joins(L, allowed_edges) + count_disconnected_joins(R, allowed_edges)

# =========================
#  è®ºæ–‡å¼ Ï†-äº¤å‰ï¼ˆä¸¥æ ¼ç‰ˆï¼‰ï¼šå§‹ç»ˆäº§å‡ºâ€œæœ‰æ•ˆæ ‘â€
# =========================
def gp_crossover_phi_strict(ind1, ind2, pset, allowed_edges,
                            max_tries=40, min_leaf_count=2):
    """
    è®ºæ–‡å®šä¹‰ï¼š
      NG1 := Ï†( postorder(T1) - postorder(S2), {S2} âˆª (leaves(T1) - leaves(S2)) )
      NG2 := Ï†( postorder(T2) - postorder(S1), {S1} âˆª (leaves(T2) - leaves(S1)) )
    ä¸¥æ ¼æ€§ï¼šé‡å¤é‡‡æ · S1,S2ï¼Œç¡®ä¿ Ï† æˆåŠŸä¸” new æ ‘æ²¡æœ‰â€œæ–­è¿ joinâ€ï¼ˆä¸äº§ç”Ÿ cross productï¼‰ã€‚
    å¤šæ¬¡å¤±è´¥åˆ™è¿”å›çˆ¶ä»£ï¼ˆno-opï¼‰ã€‚
    """
    T1 = parse_gp_str(str(ind1))
    T2 = parse_gp_str(str(ind2))

    # å¶é›†åˆå¿…é¡»ä¸€è‡´ï¼ˆä½ çš„åˆå§‹åŒ–å·²ä¿è¯ï¼‰
    if frozenset(leaves_inorder(T1)) != frozenset(leaves_inorder(T2)):
        return creator.Individual(gp.PrimitiveTree(ind1)), creator.Individual(gp.PrimitiveTree(ind2))

    def _valid_leafset(tree):
        used = get_all_tables(tree)
        return len(used) == len(set(used)) and set(used) == set(leaves_inorder(T1))

    tries = 0
    while tries < max_tries:
        tries += 1

        S1 = pick_random_proper_subtree(T1)
        S2 = pick_random_proper_subtree(T2)
        if (S1 is None) or (S2 is None):
            continue
        if min_leaf_count is not None:
            if len(leaves_set(S1)) < min_leaf_count or len(leaves_set(S2)) < min_leaf_count:
                continue

        desc_T1 = postorder_join_descriptors(T1)
        desc_S2 = descriptors_for_subtree(S2)
        nodelist1 = [d for d in desc_T1 if d not in desc_S2]
        leaves_T1 = leaves_set(T1)
        leaves_S2 = leaves_set(S2)
        Tset1 = [S2] + [t for t in leaves_T1 - leaves_S2]

        desc_T2 = postorder_join_descriptors(T2)
        desc_S1 = descriptors_for_subtree(S1)
        nodelist2 = [d for d in desc_T2 if d not in desc_S1]
        leaves_T2 = leaves_set(T2)
        leaves_S1 = leaves_set(S1)
        Tset2 = [S1] + [t for t in leaves_T2 - leaves_S1]

        NG1_tuple = phi_rebuild(nodelist1, Tset1)
        NG2_tuple = phi_rebuild(nodelist2, Tset2)

        if (NG1_tuple is None) or (NG2_tuple is None):
            continue
        if not (_valid_leafset(NG1_tuple) and _valid_leafset(NG2_tuple)):
            continue
        # ä¸¥æ ¼ï¼šä¸å…è®¸æ–­è¿ï¼ˆç­‰ä»·äºè®ºæ–‡â€œæ—  cross product / æ— äººå·¥ joinâ€çš„æœ‰æ•ˆæ€§è¦æ±‚ï¼‰
        if count_disconnected_joins(NG1_tuple, allowed_edges) != 0:
            continue
        if count_disconnected_joins(NG2_tuple, allowed_edges) != 0:
            continue

        expr1 = gp.PrimitiveTree.from_string(tuple_to_expr_str(NG1_tuple), pset)
        expr2 = gp.PrimitiveTree.from_string(tuple_to_expr_str(NG2_tuple), pset)
        return creator.Individual(expr1), creator.Individual(expr2)

    # å¤šæ¬¡å°è¯•å¤±è´¥ï¼šä¸åšäº¤å‰ï¼ˆä¸è®ºæ–‡â€œä¿æŒæœ‰æ•ˆæ€§â€çš„ç²¾ç¥ä¸€è‡´ï¼‰
    return creator.Individual(gp.PrimitiveTree(ind1)), creator.Individual(gp.PrimitiveTree(ind2))

# =========================
#  ä»£ä»·æ„ä»¶ï¼šé€‰æ‹©ç‡ä¹˜ç§¯ / ä¸è¿é€šæƒ©ç½šï¼ˆä¿æŒä¸å˜ï¼‰
# =========================
def _crossing_selectivity_product(left_subtree, right_subtree, selectivity_map, allowed_edges):
    L = _tabs(left_subtree); R = _tabs(right_subtree)
    sel = 1.0
    has = False
    for l in L:
        for r in R:
            k = frozenset([l, r])
            if k in allowed_edges:
                has = True
                sel *= selectivity_map.get(k, 1.0)
    return sel if has else None

def _anchor_penalty(left_subtree, right_subtree):
    """ domain-agnostic: ä¸å¯¹ç‰¹å®šè¡¨åšæƒ©ç½šï¼Œè¿”å› 1.0 """
    return 1.0

def estimate_cost(tree, selectivity_map, table_rows, allowed_edges=None, disconnect_penalty=1e6):
    if isinstance(tree, str):
        return table_rows.get(tree, 1)
    _, left, right = tree
    Lrows = estimate_cost(left, selectivity_map, table_rows, allowed_edges, disconnect_penalty)
    Rrows = estimate_cost(right, selectivity_map, table_rows, allowed_edges, disconnect_penalty)
    if allowed_edges is None:
        allowed_edges = build_allowed_edges(selectivity_map, _tabs(tree))
    sel = _crossing_selectivity_product(left, right, selectivity_map, allowed_edges)
    if sel is None:
        rows_out = Lrows * Rrows * disconnect_penalty
    else:
        rows_out = Lrows * Rrows * sel
        rows_out *= _anchor_penalty(left, right)
    return rows_out

def sum_join_outputs(tree, selectivity_map, table_rows, allowed_edges=None, disconnect_penalty=1e6):
    """
    è¿”å›ï¼š
      final_rows            â€” å­æ ‘æœ€ç»ˆè¾“å‡ºè¡Œæ•°
      total_generated_rows  â€” æ‰€æœ‰ JOIN èŠ‚ç‚¹ rows_out ä¹‹å’Œï¼ˆä½œä¸º fitnessï¼‰
    """
    if isinstance(tree, str):
        return table_rows.get(tree, 1), 0.0

    _, left, right = tree
    Lrows, Lsum = sum_join_outputs(left,  selectivity_map, table_rows, allowed_edges, disconnect_penalty)
    Rrows, Rsum = sum_join_outputs(right, selectivity_map, table_rows, allowed_edges, disconnect_penalty)

    if allowed_edges is None:
        all_tabs = _tabs(tree)
        allowed_edges = build_allowed_edges(selectivity_map, all_tabs)

    sel = _crossing_selectivity_product(left, right, selectivity_map, allowed_edges)
    if sel is None:
        rows_out = Lrows * Rrows * disconnect_penalty
    else:
        rows_out = Lrows * Rrows * sel
        rows_out *= _anchor_penalty(left, right)

    total_sum = Lsum + Rsum + rows_out
    return rows_out, total_sum

# =========================
#  SQL è§£æ / åŸºæ•°å‰ç§»è¿‘ä¼¼ï¼ˆä¿æŒä¸å˜ï¼‰
# =========================
def load_all_sql_queries(folder_path):
    sql_queries = {}
    for filename in sorted(os.listdir(folder_path)):
        if filename.endswith(".sql"):
            filepath = os.path.join(folder_path, filename)
            try:
                query_info = parse_sql(filepath)  # éœ€è¦è‡³å°‘ "FROM"
                sql_queries[filename] = query_info
            except Exception as e:
                print(f"[ERROR] Failed to parse {filename}: {e}")
    return sql_queries

def _collect_condition_text(query_info):
    parts = []
    for key in ("WHERE", "where", "FILTERS", "filters", "CONDITIONS"):
        v = query_info.get(key)
        if isinstance(v, str):
            parts.append(v)
        elif isinstance(v, list):
            parts.extend(map(str, v))
    for key in ("JOIN", "joins"):
        joins = query_info.get(key)
        if isinstance(joins, list):
            for j in joins:
                on = j.get("on") if isinstance(j, dict) else None
                if on:
                    parts.append(str(on))
    return " ".join(parts)

def apply_base_filters(table_rows, query_info):
    """ ä¸å†åŸºäº WHERE æ–‡æœ¬è¿›è¡Œè¡Œæ•°ç¼©æ”¾ï¼Œç›´æ¥è¿”å›åŸå§‹è¡Œæ•°ã€‚ """
    return dict(table_rows)

# =========================
#  è¿é€šåˆå§‹åŒ–/ä¿®å¤ ç›¸å…³è¾…åŠ©ï¼ˆä¿æŒä¸å˜ï¼‰
# =========================
def build_greedy_connected_order(table_list, allowed_edges, start=None):
    # æŒ‰ SQL è§£æé¡ºåºä¿åºå»é‡
    tabs = list(dict.fromkeys(table_list))
    if not tabs:
        return []

    # è®¡ç®—åº¦æ•°ï¼ˆç¨³å®šéå†ï¼‰
    deg = {t: 0 for t in tabs}
    for a in tabs:
        for b in tabs:
            if a != b and frozenset([a, b]) in allowed_edges:
                deg[a] += 1

    # é€‰èµ·ç‚¹ï¼šåº¦æ•°æœ€å¤§ï¼›å¹¶åˆ—æŒ‰ tabs é¡ºåºæ‰“ç ´
    if start in deg:
        cur = start
    else:
        max_deg = max(deg.values()) if deg else 0
        cur = next((t for t in tabs if deg[t] == max_deg), tabs[0])

    used = [cur]
    # remain ç”¨â€œæŒ‰ tabs é¡ºåºâ€çš„åˆ—è¡¨ï¼Œä¸ç”¨ set
    remain = [t for t in tabs if t != cur]

    while remain:
        # å€™é€‰æŒ‰ remain çš„ç¨³å®šé¡ºåº
        candidates = [t for t in remain
                      if any(frozenset([t, u]) in allowed_edges for u in used)]
        if candidates:
            # é€‰è¿æ¥æ•°æœ€å¤šçš„ï¼›å¹¶åˆ—ä¿ç•™å€™é€‰å‡ºç°é¡ºåº
            best_score = -1
            best_idx = 0
            for i, t in enumerate(candidates):
                score = sum(1 for u in used if frozenset([t, u]) in allowed_edges)
                if score > best_score:
                    best_score = score
                    best_idx = i
            next_t = candidates[best_idx]
        else:
            # ä»¥å‰æ˜¯ random.choice(...)ï¼›ç°åœ¨å–ç¬¬ä¸€ä¸ªï¼Œä¿è¯ç¡®å®šæ€§
            next_t = remain[0]

        used.append(next_t)
        remain = [t for t in remain if t != next_t]

    return used


def repair_individual_connected(individual, pset, table_list, allowed_edges):
    shape = parse_gp_str(str(individual))
    if isinstance(shape, str):
        return creator.Individual(gp.PrimitiveTree(individual))
    shape_leaves = leaves_inorder(shape)
    if len(shape_leaves) != len(table_list):
        return creator.Individual(gp.PrimitiveTree(individual))
    if count_disconnected_joins(shape, allowed_edges) == 0:
        return creator.Individual(gp.PrimitiveTree(individual))
    order = build_greedy_connected_order(table_list, allowed_edges)
    fixed_tuple = fill_leaves_with_order(shape, iter(order))
    expr = gp.PrimitiveTree.from_string(tuple_to_expr_str(fixed_tuple), pset)
    return creator.Individual(expr)

# =========================
#  ä¼˜åŒ–ä¸»æµç¨‹ï¼ˆä¿æŒä¸å˜ï¼Œä»… mate æ”¹ä¸ºä¸¥æ ¼ Ï†-äº¤å‰ï¼‰
# =========================
def optimize_query(query_info, selectivity_map, table_rows, filename="(unknown)",
                   seed=None, summary_file="summary_best_results_seeds.csv", log_dir="logs_seeds"):
    # ---- æ§åˆ¶å‚æ•°ï¼ˆä¿æŒä¸å˜ï¼‰ ----
    EARLY_STOP = False
    PATIENCE = 15
    MIN_DELTA_REL = 1e-3
    MIN_DELTA_ABS = 1e-6

    PENALTY_START = 1e5
    PENALTY_END   = 1e6
    ANNEAL_UNTIL_GEN = 40

    POP_SIZE = 50
    NGEN = 50
    ELITE_NUM = 2
    CXPB = 0.3
    MUTPB = 0.6
    TOURN = 2

    if seed is not None:
        random.seed(seed)

    table_list = list(dict.fromkeys(query_info["FROM"]))  # å»é‡
    if len(table_list) < 2:
        print(f"Query {filename} has less than 2 tables. Skipping.")
        return

    base_rows = apply_base_filters(table_rows, query_info)
    allowed_edges = build_allowed_edges(selectivity_map, table_list)

    pset = create_pset(table_list)
    if not hasattr(creator, "FitnessMin"):
        creator.create("FitnessMin", base.Fitness, weights=(-1.0,))
    if not hasattr(creator, "Individual"):
        creator.create("Individual", gp.PrimitiveTree, fitness=creator.FitnessMin)

    toolbox = base.Toolbox()
    toolbox.register("clone", deepcopy)
    # åˆå§‹åŒ–ï¼šå°½é‡è¿é€šï¼ˆä¿æŒä¸å˜ï¼‰
    import hashlib

    # ä¸ºæ¯ä¸ªåˆå§‹ä¸ªä½“åˆ†é…ç¨³å®šçš„å±€éƒ¨ RNGï¼šå— (filename, seed, ä¸ªä½“åºå·) å†³å®š
    _ind_counter = {"i": 0}

    def _stable_subseed(label: str, fname: str, master_seed: int, idx: int) -> int:
        s = f"{label}|{fname}|{master_seed}|{idx}".encode("utf-8")
        h = hashlib.md5(s).digest()  # ç¨³å®šå“ˆå¸Œï¼Œä¸å— PYTHONHASHSEED å½±å“
        return int.from_bytes(h[:4], "big")  # å– 32bit å­ç§å­

    def _expr_wrapper():
        i = _ind_counter["i"]
        _ind_counter["i"] += 1
        local_seed = _stable_subseed("INIT", filename, int(seed if seed is not None else 0), i)
        rng = random.Random(local_seed)
        return generate_expr_connected(pset, table_list, allowed_edges, rng)

    toolbox.register("expr", _expr_wrapper)
    toolbox.register("individual", tools.initIterate, creator.Individual, toolbox.expr)
    toolbox.register("population", tools.initRepeat, list, toolbox.individual)

    current_penalty = PENALTY_START

    def _valid_leafset(tree):
        used = get_all_tables(tree)
        return len(used) == len(table_list) and set(used) == set(table_list)

    def _try_repair_leafset(tree):
        """å°½é‡ä¿®å¤ä¸ºæ¯è¡¨æ°å¥½ä¸€æ¬¡ï¼›å¤±è´¥è¿”å› Noneã€‚"""
        try:
            order = build_greedy_connected_order(table_list, allowed_edges)
            fixed = fill_leaves_with_order(tree, iter(order))
            if _valid_leafset(fixed):
                return fixed
            fixed2 = fill_leaves_with_order(tree, iter(table_list))
            if _valid_leafset(fixed2):
                return fixed2
        except Exception:
            pass
        return None

    def eval_cost(individual):
        try:
            tree = parse_gp_str(str(individual))

            if not _valid_leafset(tree):
                repaired = _try_repair_leafset(tree)
                if repaired is None:
                    return (1e300,)
                tree = repaired

            _, total_sum = sum_join_outputs(
                tree, selectivity_map, base_rows,
                allowed_edges=allowed_edges,
                disconnect_penalty=current_penalty
            )
            if not (total_sum == total_sum) or total_sum == float("inf") or total_sum == float("-inf"):
                return (1e300,)
            return (float(total_sum),)
        except Exception as e:
            s = str(individual)
            print(f"[EVAL-ERR] {filename} seed={seed}: {e} | ind[:120]={s[:120]}")
            return (1e300,)

    toolbox.register("evaluate", eval_cost)
    toolbox.register("select", tools.selTournament, tournsize=TOURN)

    # === mateï¼šæ”¹ä¸ºâ€œä¸¥æ ¼ Ï†-äº¤å‰â€ï¼Œä¸å†å›é€€åˆ° cxOnePointï¼›å¤±è´¥åˆ™ no-op ===
    toolbox.register("mate", gp_crossover_phi_strict, pset=pset, allowed_edges=allowed_edges)

    toolbox.register("expr_mut", gp.genFull, min_=0, max_=5)
    toolbox.register("mutate", mutate_individual, pset=pset, table_list=table_list)

    print(f"\nğŸ§ª Optimizing Query: {filename} | Seed: {seed}  (Tables: {table_list})")
    pop = toolbox.population(n=POP_SIZE)

    # åˆå§‹åŒ–ååšä¸€æ¬¡è¿é€šä¿®å¤ + åˆæ³•æ€§ä¿éšœï¼ˆä¿æŒä¸å˜ï¼‰
    def _legalize(ind):
        try:
            ind2 = repair_individual_connected(ind, pset, table_list, allowed_edges)
        except Exception:
            ind2 = creator.Individual(gp.PrimitiveTree(ind))
        t = parse_gp_str(str(ind2))
        if not _valid_leafset(t):
            return creator.Individual(gp.PrimitiveTree(ind))
        return ind2

    pop = [_legalize(ind) for ind in pop]

    hof = tools.HallOfFame(1)

    # åˆè¯„
    fits0 = list(map(toolbox.evaluate, pop))
    for ind, fit in zip(pop, fits0):
        ind.fitness.values = fit
    hof.update(pop)

    # === è®°å½• Generation 0ï¼ˆåˆå§‹åŒ–ç§ç¾¤ï¼‰çš„æœ€ä½³ä¸ªä½“ä¸ cost ===
    log_data = []  # ç¡®ä¿åˆ—è¡¨å·²åˆå§‹åŒ–
    # è®°å½•ç¬¬0ä»£ç§ç¾¤ä¸­çš„æœ€ä¼˜è§£
    gen0_best = min(pop, key=lambda x: x.fitness.values[0] if x.fitness.valid else float('inf'))
    gen0_best_cost = gen0_best.fitness.values[0] if gen0_best.fitness.valid else toolbox.evaluate(gen0_best)[0]
    raw0 = parse_gp_str(str(gen0_best))
    
    # ä¸åç»­ logging å¯¹é½ï¼šå¦‚å¶é›†åˆä¸åˆæ³•ï¼Œå°è¯•ä¿®å¤ä¸€æ¬¡
    if not _valid_leafset(raw0):
        fixed0 = _try_repair_leafset(raw0)
        gen0_best_tree = fixed0 if fixed0 is not None else raw0
    else:
        gen0_best_tree = raw0
        
    log_data.append(
        (seed, 0, gen0_best_cost, tuple_to_expr_str(gen0_best_tree), ",".join(get_all_tables(gen0_best_tree)))
    )
    mu = len(pop)
    lmbda = mu

    best_seen = float("inf")
    no_improve = 0

    def _anneal_penalty(gen_idx):
        if gen_idx >= ANNEAL_UNTIL_GEN:
            return PENALTY_END
        t = gen_idx / float(ANNEAL_UNTIL_GEN)
        return PENALTY_START + (PENALTY_END - PENALTY_START) * t

    for gen in range(1, NGEN + 1):
        current_penalty = _anneal_penalty(gen)

        parents = toolbox.select(pop, k=mu)
        offspring = algorithms.varOr(parents, toolbox, lambda_=lmbda, cxpb=CXPB, mutpb=MUTPB)

        # äº¤å‰/å˜å¼‚åï¼šè¿é€šä¿®å¤ + åˆæ³•åŒ–ï¼ˆä¿æŒä¸å˜ï¼‰
        new_offspring = []
        for ind in offspring:
            try:
                ind = repair_individual_connected(ind, pset, table_list, allowed_edges)
            except Exception:
                ind = creator.Individual(gp.PrimitiveTree(ind))
            t = parse_gp_str(str(ind))
            if not _valid_leafset(t):
                fixed = _try_repair_leafset(t)
                if fixed is not None:
                    ind = creator.Individual(gp.PrimitiveTree.from_string(tuple_to_expr_str(fixed), pset))
                else:
                    ind = creator.Individual(gp.PrimitiveTree(ind))
            new_offspring.append(ind)
        offspring = new_offspring

        fits = list(map(toolbox.evaluate, offspring))
        for ind, fit in zip(offspring, fits):
            ind.fitness.values = fit

        pop = offspring

        # ç²¾è‹±æ³¨å…¥ï¼ˆä¿æŒä¸å˜ï¼‰
        if len(hof) > 0:
            inj = min(ELITE_NUM, len(hof), len(pop))
            pop[:inj] = [deepcopy(h) for h in hof[:inj]]

        hof.update(pop)
        
        # è®°å½•å½“å‰ä»£ç§ç¾¤ä¸­çš„æœ€ä¼˜è§£ï¼ˆè€Œä¸æ˜¯å†å²æœ€ä¼˜ï¼‰
        current_best = min(pop, key=lambda x: x.fitness.values[0] if x.fitness.valid else float('inf'))
        current_best_cost = current_best.fitness.values[0] if current_best.fitness.valid else toolbox.evaluate(current_best)[0]
        raw = parse_gp_str(str(current_best))
        if not _valid_leafset(raw):
            fixed = _try_repair_leafset(raw)
            current_best_tuple = fixed if fixed is not None else raw
        else:
            current_best_tuple = raw

        current_best_tables = get_all_tables(current_best_tuple)
        log_data.append((seed, gen, current_best_cost, tuple_to_expr_str(current_best_tuple), ",".join(current_best_tables)))

        # Early stopping ï¼ˆä¿æŒä¸å˜ï¼›é»˜è®¤ä¸å¯ç”¨ï¼‰
        if EARLY_STOP:
            import math
            if best_seen is None or not math.isfinite(best_seen):
                best_seen = current_best_cost
                no_improve = 0
            else:
                threshold = max(MIN_DELTA_ABS, abs(best_seen) * MIN_DELTA_REL)
                improved = current_best_cost < (best_seen - threshold)
                if improved:
                    best_seen = current_best_cost
                    no_improve = 0
                else:
                    MIN_EARLY_GEN = 10
                    if gen >= MIN_EARLY_GEN:
                        no_improve += 1
                        if no_improve >= PATIENCE:
                            print(f"[EARLY-STOP] {filename} seed={seed} at gen {gen}, best={best_seen:.6g}")
                            break

    # å†™æ—¥å¿—ï¼ˆç»“æ„ä¸å˜ï¼‰
    os.makedirs(log_dir, exist_ok=True)
    log_file = os.path.join(log_dir, f"{filename}_seed{seed}_log.csv")
    with open(log_file, "w", newline="", encoding="utf-8") as f:
        writer = csv.writer(f)
        writer.writerow(["Seed", "Generation", "Best_Cost", "Best_Join_Tree_Str", "Used_Tables"])
        writer.writerows(log_data)

    # æ±‡æ€»ï¼ˆç»“æ„ä¸å˜ï¼‰
    new_summary = not os.path.exists(summary_file)
    best = hof[0]
    raw = parse_gp_str(str(best))
    if not _valid_leafset(raw):
        fixed = _try_repair_leafset(raw)
        best_tree_tuple = fixed if fixed is not None else raw
    else:
        best_tree_tuple = raw
    best_cost = eval_cost(best)[0] if not best.fitness.valid else best.fitness.values[0]
    best_tables = get_all_tables(best_tree_tuple)
    tree_str = tuple_to_expr_str(best_tree_tuple)
    with open(summary_file, "a", newline="", encoding="utf-8") as f:
        writer = csv.writer(f)
        if new_summary:
            writer.writerow(["SQL_File", "Seed", "Best_Cost", "Best_Join_Tree_Str", "Table_Order"])
        writer.writerow([filename, seed, best_cost, tree_str, ",".join(best_tables)])

# =========================
#  ä¸»æ‰§è¡Œï¼ˆè¾“å‡ºæ–‡ä»¶åä¿æŒâ€œbaselineâ€ï¼‰
# =========================
if __name__ == "__main__":
    # æ³¨æ„ï¼šä¸å›ºå®šå…¨å±€éšæœºç§å­ï¼›æ¯æ¬¡è¿è¡Œéƒ½ä¼šæŠ½å–æ–°çš„ 30 ä¸ª seed
    selectivity_map, table_rows = load_selectivity_with_rows("Join-Selectivities.xlsx")
    all_queries = load_all_sql_queries("TestQueries")

    # ä½¿ç”¨å›ºå®šçš„ seeds_used.txt æ–‡ä»¶ä¸­çš„ seed
    seeds = []
    if os.path.exists("seeds_used.txt"):
        with open("seeds_used.txt", "r", encoding="utf-8") as f:
            for line in f:
                line = line.strip()
                if line:
                    seeds.append(int(line))
        print(f"ä½¿ç”¨ seeds_used.txt ä¸­çš„ {len(seeds)} ä¸ªç§å­")
    else:
        print("é”™è¯¯: seeds_used.txt æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¯·ç¡®ä¿è¯¥æ–‡ä»¶å­˜åœ¨å¹¶åŒ…å«ç§å­å€¼")
        exit(1)

    # å¤š seed Ã— å¤šæŸ¥è¯¢è¿è¡Œ â€”â€” baseline åŒºåˆ†æ–‡ä»¶åä¸å˜
    for filename, query_info in all_queries.items():
        for s in seeds:
            try:
                optimize_query(
                    query_info, selectivity_map, table_rows,
                    filename=filename,
                    seed=s,
                    summary_file="summary_best_results_seeds_baseline.csv",
                    log_dir="logs_seeds_baseline"
                )
            except Exception as e:
                print(f"[BASELINE-ERROR] Optimizing {filename} with seed {s} failed: {e}")